% File: red_diff.tex

\subsection{RED-Diff: Regularization by Denoising Diffusion}

% What RED-Diff does
\begin{frame}{What RED-Diff Does}
  RED-Diff solves noisy inverse problems by combining:
  \begin{itemize}
    \item A fidelity term to bring the reconstruction closer to the observations $y$,
    \item A regularizer based on the multiscale denoisers of a pretrained diffusion model,
  \end{itemize}
  integrating constraints at multiple levels of detail to preserve both global structures and fine details.
\end{frame}

% Implementation of RED-Diff
\begin{frame}[fragile]{Implementation of RED-Diff}
  The algorithm is structured into three main phases:
  \begin{enumerate}
    \item \textbf{Initialization:} $\mu^{(0)} = K^T y$.
    \item \textbf{Iterative Optimization:}
      For each step $i=1,\dots,N$ and for each noise level $t=1,\dots,T$:
      \begin{enumerate}
        \item Sample $\epsilon\sim\mathcal{N}(0,I)$ and construct
          \[x_t = \sqrt{\alpha_t}\,\mu^{(i-1)} + \sigma_t\,\epsilon.\]
        \item Predict the noise $\hat\epsilon = \epsilon_\theta(x_t,t)$.
        \item Compute the loss terms:
          \[
            L_{\mathrm{fid}} = \tfrac{1}{2\sigma_y^2}\|K\mu^{(i-1)} - y\|^2,
            \quad
            L_{\mathrm{reg}} = w_t\,\|\hat\epsilon - \epsilon\|^2,
            \quad w_t = 1/\mathrm{SNR}_t.
          \]
      \end{enumerate}
      Then update $\mu^{(i)}$ using Adam to minimize $L_{\mathrm{fid}} + \lambda\,L_{\mathrm{reg}}$.
    \item \textbf{Output:} the final estimate $\mu^{(N)}$.
  \end{enumerate}
\end{frame}

% Final results of RED-Diff
\begin{frame}{Final Results}
  \begin{itemize}
    \item On deblurring tests, RED-Diff achieves an average PSNR of approximately $19.4\,$dB and SSIM of approximately $0.64$.
    \item Compared to methods without a diffusion prior, it improves reconstruction quality by more than $2\,$dB in PSNR.
    \item Reconstructions show sharper details and fewer artifacts thanks to the multiscale integration of denoising.
  \end{itemize}
\end{frame}
