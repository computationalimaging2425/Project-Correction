% Frame: What DPS Does
\begin{frame}{DPS: Diffusion Posterior Sampling}
  Diffusion Posterior Sampling (DPS) is a method for solving noisy inverse problems by leveraging diffusion models as an implicit prior.
  \begin{itemize}
    \item Starting from a corrupted image $y = K(x_0) + n$, it directly integrates the likelihood term into the reverse diffusion sampling process.
    \item At step $t$, DPS computes a prediction $\hat x_0$ and uses the gradient of $\|y - K(\hat x_0)\|^2$ to move towards solutions consistent with the observed data.
    \item Compared to hard projection methods, DPS keeps the trajectory on the generative manifold, reducing noise amplification.
  \end{itemize}
\end{frame}

% Frame: Implementation of DPS
\begin{frame}[fragile]{Implementation of DPS}
  The algorithm consists of three main phases:
  \begin{enumerate}
    \item \textbf{Initial prediction:} Sample $x_T \sim \mathcal{N}(0, I)$, then for each step $t$, the UNet model estimates the noise $s_\theta(x_t, t)$ and reconstructs $\hat x_0$.
    \item \textbf{Posterior update:} Compute the likelihood gradient $\nabla = -K^T(y - K(\hat x_0))$ and apply a step proportional to $\gamma_t = \frac{1 - \bar\alpha_t}{\sigma_y^2 + (1 - \bar\alpha_t)}$ to obtain $\tilde x_{t-1}$.
    \item \textbf{Modified DDIM step:} Using $\tilde x_{t-1}$ as a reference, perform the standard DDIM update to move to $x_{t-1}$, preserving the effect of the likelihood gradient.
  \end{enumerate}
  \vspace{0.5em}
  The implementation requires only a few steps in PyTorch, integrating blur functions and their adjoint operators.
\end{frame}

% Frame: Final Results
\begin{frame}{Final Results}
\end{frame}